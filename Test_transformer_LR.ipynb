{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mThe kernel died. Error: ... View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import os, sys\n",
    "import logging\n",
    "import random\n",
    "import h5py\n",
    "import shutil\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import sigpy.plot as pl\n",
    "import torch\n",
    "import sigpy as sp\n",
    "import torchvision\n",
    "from torch import optim\n",
    "import scipy.ndimage\n",
    "from scipy.ndimage import binary_closing\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch.nn import functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib\n",
    "# import custom libraries\n",
    "from utils import transforms as T\n",
    "from utils import subsample as ss\n",
    "from utils import complex_utils as cplx\n",
    "from utils.resnet2p1d import generate_model\n",
    "from utils.flare_utils import roll\n",
    "from utils import data_ut as dut\n",
    "# import custom classes\n",
    "from utils.datasets import SliceData\n",
    "from subsample_fastmri import MaskFunc\n",
    "from MoDL_single import UnrolledModel\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import nibabel as nib\n",
    "from models.SAmodel import MyNetwork\n",
    "from models.Unrolled import Unrolled\n",
    "from ImageFusion_Dualbranch_Fusion.densefuse_net import DenseFuseNet\n",
    "from ImageFusion_Dualbranch_Fusion.channel_fusion import channel_f as channel_fusion\n",
    "from fastmri.data import transforms, subsample\n",
    "from RCAN import CombinedNetwork\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "%load_ext autoreload\n",
    "%autoreload 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!which python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Path to your NIfTI file\n",
    "# Original Slice\n",
    "nii_file_target = './test_data/patient29b/T1_week152reg.nii'\n",
    "nii_file_ref = './test_data/patient29b/T1_week165regT1_week152.nii'\n",
    "\n",
    "\n",
    "img_target = nib.load(nii_file_target)\n",
    "img_ref = nib.load(nii_file_ref)\n",
    "\n",
    "target = img_target.get_fdata()[...,20]\n",
    "reference = img_ref.get_fdata()[...,20]\n",
    "\n",
    "random_phase = torch.angle(T.random_map((1,256,160), 'cpu',kspace_radius_range=(0.001, 0.001))) \n",
    "target = target * (torch.exp(1j * random_phase)).numpy() \n",
    "target = target.squeeze(0)\n",
    "target_torch = cplx.to_tensor(target).float() \n",
    "reference_torch = cplx.to_tensor(reference).float() \n",
    "reference_kspace_torch = T.fft2(reference_torch)\n",
    "reference_kspace = cplx.to_numpy(reference_kspace_torch)\n",
    "kspace_torch = T.fft2(target_torch)\n",
    "target = cplx.to_numpy(target_torch)\n",
    "kspace = cplx.to_numpy(kspace_torch)\n",
    "\n",
    "# Print the shape of the data to verify\n",
    "print(target_torch.shape)\n",
    "mask2 = sp.mri.poisson((256,160),5, calib=(18,14), dtype=float, crop_corner=False, return_density=True, seed=0, max_attempts=6, tol=0.01)\n",
    "mask2[128-10:128+9,80-8:80+7] = 1\n",
    "mask_torch = torch.stack([torch.tensor(mask2).float(),torch.tensor(mask2).float()],dim=2)\n",
    "\n",
    "mask_torch = T.kspace_crop(mask_torch,0.67)\n",
    "kspace_torch = T.awgn_torch(kspace_torch,10,L=1)\n",
    "kspace_torch = T.kspace_crop(kspace_torch,0.67)\n",
    "\n",
    "print(kspace_torch.shape)\n",
    "print(mask_torch.shape)\n",
    "kspace_torch = kspace_torch*mask_torch\n",
    "\n",
    "s = (256/1.5)*(160/1.5)\n",
    "print((torch.sum(mask_torch))/s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_lowres = abs(sp.ifft(sp.resize(sp.resize(kspace,(256,24)),(256,160))))\n",
    "magnitude_vals = im_lowres.reshape(-1)\n",
    "k = int(round(0.05 * magnitude_vals.shape[0]))\n",
    "scale = magnitude_vals[magnitude_vals.argsort()[::-1][k]]\n",
    "kspace = kspace/scale\n",
    "target = target/scale\n",
    "\n",
    "# Apply kspace crop on target\n",
    "target_torch = cplx.to_tensor(target)\n",
    "target_torch = T.ifft2( T.kspace_cut(T.fft2(target_torch),0.67,0.67))\n",
    "# For plot\n",
    "kspace_HR = np.abs(cplx.to_numpy(T.fft2(cplx.to_tensor(target))))\n",
    "kspace_LR =cplx.to_numpy( T.kspace_crop(T.fft2( cplx.to_tensor(target)),0.67))\n",
    "target_HR = target\n",
    "target_LR = cplx.to_numpy(T.ifft2( T.kspace_crop(T.fft2( cplx.to_tensor(target)),0.67)))\n",
    "target = cplx.to_numpy(target_torch)\n",
    "# Convert everything from numpy arrays to tensors\n",
    "kspace_torch = cplx.to_tensor(kspace).float()\n",
    "#kspace_torch = T.awgn_torch(kspace_torch,10,L=1)\n",
    "kspace_noised = kspace_torch.clone()\n",
    "kspace_noised = T.kspace_cut(kspace_noised,0.67,0.67)\n",
    "kspace_torch = T.kspace_cut(kspace_torch,0.67,0.67)\n",
    "target_torch = cplx.to_tensor(target).float()\n",
    "\n",
    "### Reference addition ###\n",
    "im_lowres_ref = abs(sp.ifft(sp.resize(sp.resize(reference_kspace,(256,24)),(256,160))))\n",
    "magnitude_vals_ref = im_lowres_ref.reshape(-1)\n",
    "k_ref = int(round(0.05 * magnitude_vals_ref.shape[0]))\n",
    "scale_ref = magnitude_vals_ref[magnitude_vals_ref.argsort()[::-1][k_ref]]\n",
    "reference = reference / scale_ref\n",
    "reference_torch = cplx.to_tensor(reference).float()\n",
    "reference_torch_kspace = T.fft2(reference_torch)\n",
    "reference_torch_kspace = T.kspace_cut(reference_torch_kspace,0.67,0.67)\n",
    "reference_torch = T.ifft2(reference_torch_kspace)\n",
    "\n",
    "#kspace_torch = kspace_torch*mask_torch\n",
    "\n",
    "def get_mask_func(factor):\n",
    "    center_fractions = 0.08 * 4/factor # RandomMaskFuncEquiSpacedMaskFunc\n",
    "    mask_func = subsample.EquiSpacedMaskFunc(\n",
    "    center_fractions=[center_fractions],\n",
    "    accelerations=[factor], \n",
    "    )\n",
    "    return mask_func\n",
    "mask_func = get_mask_func(3)\n",
    "kspace_torch = transforms.apply_mask(kspace_torch, mask_func)[0]\n",
    "\n",
    "concat = np.concatenate((target,cplx.to_numpy(T.ifft2(kspace_noised)),np.abs(cplx.to_numpy(kspace_torch))!=0,cplx.to_numpy(T.ifft2(kspace_torch))),axis=1)\n",
    "fig, axs = plt.subplots(1, 1, figsize=(20, 5))  # 1 row, 3 columns\n",
    "# Plot each image in a subplot\n",
    "im1 = axs.imshow(np.abs(concat), cmap='gray')\n",
    "#im1 = axs.imshow(np.log(np.abs(cplx.to_numpy(kspace_torch))), cmap='gray')\n",
    "plt.title('     Low-Res scan                      Low-Res Noised scan                 Kspace Sampling mask, R=3          synthetic Low-Field scan')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize=(10, 5))  # 1 row, 3 columns\n",
    "concat2 = np.concatenate((cplx.to_numpy(target_torch),cplx.to_numpy(reference_torch)),axis=1)\n",
    "im1 = axs.imshow(np.abs(concat2), cmap='gray')\n",
    "#im1 = axs.imshow(np.log(np.abs(cplx.to_numpy(kspace_torch))), cmap='gray')\n",
    "plt.title('Visit 2                 Visit 1')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\"\"\"\n",
    "concat = np.concatenate((target_HR,target_LR),axis=1)\n",
    "fig, axs = plt.subplots(1, 1, figsize=(6, 5))  # 1 row, 3 columns\n",
    "# Plot each image in a subplot\n",
    "im1 = axs.imshow(np.abs(concat), cmap='gray')\n",
    "#im1 = axs.imshow(np.log(np.abs(cplx.to_numpy(kspace_torch))), cmap='gray')\n",
    "plt.title(' High-Res scan (1x1[mm])        Low-Res scan (1.5x1.5[mm])   ')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "concat = np.concatenate((kspace_HR,kspace_LR),axis=1)\n",
    "fig, axs = plt.subplots(1, 1, figsize=(6, 5))  # 1 row, 3 columns\n",
    "# Plot each image in a subplot\n",
    "im1 = axs.imshow(np.log(np.abs(concat)), cmap='gray')\n",
    "#im1 = axs.imshow(np.log(np.abs(cplx.to_numpy(kspace_torch))), cmap='gray')\n",
    "plt.title(' High-Res kspace (1x1[mm])        Low-Res kspace (1.5x1.5[mm])   ')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\"\"\"\n",
    "mask_np = np.abs(cplx.to_numpy(kspace_torch))!=0\n",
    "print(f'Mask torch size: {mask_np.shape}')\n",
    "s = (172)*(108)\n",
    "print(f'Acceleration factor R: {np.sum(mask_np)/s}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Namespace:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyper parameters\n",
    "params = Namespace()\n",
    "#params.data_path = \"./registered_data/patient23b/\"\n",
    "params.data_path = \"./registered_data/\"\n",
    "params.batch_size = 2\n",
    "params.num_grad_steps = 1 #4\n",
    "params.num_cg_steps = 8 #8\n",
    "params.share_weights = True\n",
    "params.modl_lamda = 0.05\n",
    "params.lr = 0.00001\n",
    "#params.lr = 0.0001\n",
    "params.weight_decay = 0\n",
    "params.lr_step_size = 7\n",
    "params.lr_gamma = 0.1\n",
    "params.epoch = 61\n",
    "params.reference_mode = 1\n",
    "params.reference_lambda = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "checkpoint_file = \"./L2_checkpoints_poisson_x2_ViT_LR_tests2/model_20.pt\"\n",
    "\n",
    "checkpoint = torch.load(checkpoint_file,map_location=device)\n",
    "# Init model\n",
    "from vision_transformer import VisionTransformer\n",
    "from recon_net import ReconNet\n",
    "\n",
    "#from UnrolledViT import UnrolledViT\n",
    "from UnrolledViT import UnrolledViT\n",
    "model = UnrolledViT(params).to(device)\n",
    "\n",
    "# load checkpoint for ViT\n",
    "#cp = torch.load('./lsdir-2x+hq50k_vit_epoch_60.pt', map_location=device)\n",
    "#checkpoint_file = \"./L2_checkpoints_poisson_x2_FusionNetViT/model_30.pt\"\n",
    "\n",
    "model.load_state_dict(checkpoint['model'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "img = cplx.to_tensor(np.abs(cplx.to_numpy(T.ifft2(kspace_torch)))).permute(2,0,1).unsqueeze(0).to(device)\n",
    "img_chan = img[:,0,:,:].unsqueeze(0)\n",
    "ref = cplx.to_tensor(np.abs(cplx.to_numpy(reference_torch))).permute(2,0,1).unsqueeze(0).to(device)\n",
    "ref_chan = ref[:,0,:,:].unsqueeze(0)\n",
    "ref_np = ref_chan.cpu().numpy()[0,0,:,:]\n",
    "img_padded_np = img_chan.cpu().numpy()[0,0,:,:]\n",
    "\n",
    "\n",
    "im_out = model(kspace_torch.float().unsqueeze(0).to(device),reference_torch.float().unsqueeze(0).to(device)).squeeze(0)\n",
    "im_out_pad = torch.cat((im_out,torch.zeros_like(im_out)),dim=2)\n",
    "im_out = T.ifft2(T.fft2(im_out_pad))\n",
    "target_torch = T.ifft2(T.fft2(cplx.to_tensor(target)))\n",
    "target = cplx.to_numpy(target_torch.cpu().detach())\n",
    "im_out = np.abs(cplx.to_numpy(im_out.cpu().detach()))\n",
    "\n",
    "# Concatenate images horizontally\n",
    "concatenated_image = np.concatenate((ref_np,img_padded_np, im_out,np.abs(target)),axis=1)\n",
    "# Plot the concatenated image\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(concatenated_image, cmap='gray')\n",
    "plt.title('Reference                          Input                              recon                            target')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kspace_torch.shape\n",
    "reference_torch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity as ssim\n",
    "from scipy.ndimage import binary_fill_holes\n",
    "def compute_psnr(img1, img2, maxval):\n",
    "    \"\"\"Computes PSNR in dB\"\"\"\n",
    "    mse = np.mean((img1 - img2) ** 2)\n",
    "\n",
    "    return (10 * np.log10(maxval / mse)).item()\n",
    "cplx_image_target = target\n",
    "cplx_image_in = img_padded_np\n",
    "cplx_image_out = im_out\n",
    "\n",
    "cplx_image_reference = ref_np\n",
    "maxval = np.max(np.abs(np.concatenate((cplx_image_target,cplx_image_in,cplx_image_out),axis=0)))\n",
    "minval = np.min(np.abs(np.concatenate((cplx_image_target,cplx_image_in,cplx_image_out),axis=0)))\n",
    "\n",
    "target_numpy_norm = np.abs(cplx_image_target)/maxval\n",
    "input_numpy_norm = np.abs(cplx_image_in)/maxval\n",
    "out_numpy_norm = np.abs(cplx_image_out)/maxval\n",
    "\n",
    "# Area calib\n",
    "# Find comparison area:\n",
    "area = target_numpy_norm > 0.30\n",
    "kernel = np.ones((10, 10)) / 25.0\n",
    "#area = np.convolve(area, kernel, mode='constant', cval=0.0)\n",
    "area = scipy.ndimage.convolve(area.astype(float), kernel, mode='constant', cval=0.0)\n",
    "area[area>0.009] = 1\n",
    "structuring_element = np.ones((4,4))\n",
    "area = binary_closing(area, structure=structuring_element)\n",
    "area = binary_fill_holes(area)\n",
    "\n",
    "target_numpy_norm = target_numpy_norm * area\n",
    "input_numpy_norm = input_numpy_norm * area\n",
    "out_numpy_norm = out_numpy_norm * area\n",
    "\n",
    "\n",
    "psnr_in = compute_psnr(target_numpy_norm, input_numpy_norm,1)\n",
    "psnr_out = compute_psnr(target_numpy_norm,out_numpy_norm,1)\n",
    "data_range = maxval - minval\n",
    "ssim_in, _ = ssim(target_numpy_norm, input_numpy_norm, data_range=data_range, full=True)\n",
    "ssim_out, _ = ssim(target_numpy_norm, out_numpy_norm, data_range=data_range, full=True)\n",
    "\n",
    "plt_concat = np.concatenate((np.abs(cplx_image_reference),np.abs(cplx_image_in),np.abs(cplx_image_out),np.abs(cplx_image_target)),axis=1)\n",
    "fig, axs = plt.subplots(1, 1, figsize=(20, 5))  # 1 row, 3 columns\n",
    "im = axs.imshow(plt_concat, cmap='gray')\n",
    "axs.set_title(f'Reference                 Input (SSIM: {ssim_in:.2f})               Output (SSIM: {ssim_out:.2f})               Target')\n",
    "#axs.set_title(f'Reference                         Input                         Output                                 Target')\n",
    "fig.colorbar(im, ax=axs)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(cplx_image_target.shape)\n",
    "print(cplx_image_in.shape)\n",
    "print(cplx_image_out.shape)\n",
    "# Create a figure and axes\n",
    "kspace_in = cplx.to_numpy(kspace_torch)\n",
    "kspace_out = cplx.to_numpy(T.fft2((cplx.to_tensor(cplx_image_out))))\n",
    "kspace_target = cplx.to_numpy(T.fft2((cplx.to_tensor(cplx_image_target))))\n",
    "\n",
    "plt_concat = np.concatenate((kspace_in,kspace_out,kspace_target),axis=1)\n",
    "fig, axs = plt.subplots(1, 1, figsize=(15, 5))  # 1 row, 3 columns\n",
    "im = axs.imshow(np.log(np.abs(plt_concat)), cmap='gray')\n",
    "axs.set_title('Input                               Output                              Target')\n",
    "fig.colorbar(im, ax=axs)\n",
    "plt.show()\n",
    "\n",
    "pl.ImagePlot(np.log(np.abs(plt_concat).astype(float)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
